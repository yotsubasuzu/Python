{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XV-HVmVVkopV"
   },
   "source": [
    "## Lab Introduction\n",
    "Growing up, everyone has a hero. For many people, that hero was Muhammad Ali. He taught people it was okay to be proud of who they were, at a time when others would not accept that. He showed people how to stand up for their beliefs in the face of oppression and tyranny. He made people value themselves, and encouraged them care for those around them. He showed us what bravery truly meant, how to be a heck of a boxer, and so much more. Every single person who met Muhammad Ali, either in the ring or outside of it, had a motivating story to share about their encounter.\n",
    "\n",
    "On June 3, 2016, Muhammad Ali passed away at the age of 74 due to septic shock. Thirty years earlier, he was diagnosed with Parkinson's syndrome, a neurodegenerative condition that doctors attributed to his boxing-related brain injuries.\n",
    "\n",
    "Parkinson's disease itself is a long-term disorder of the nervous system that affects many aspects of a person's mobility over time. It's characterized by shaking, slowed movement, rigidity, dementia, and depression. In 2013, some 53 million people were diagnosed with it, mostly men. Other famous personalities affected by it include actor Michael J. Fox, and olympic cyclist Davis Phinney.\n",
    "\n",
    "In this lab, you will be applying SVC to the [Parkinson's Data Set](https://archive.ics.uci.edu/ml/datasets/Parkinsons), provided courtesy of UCI's Machine Learning Repository. The dataset was created at the University of Oxford, in collaboration with 10 medical centers around the US, along with Intel who developed the device used to record the primary features of the dataset: speech signals. Your goals for this lab are first to see if it's possible to differentiate between people who have Parkinson's and who don't using SciKit-Learn's support vector classifier, and then to take a first-stab at a naive way of fine-tuning your parameters in an attempt to maximize the accuracy of your testing set.\n",
    "\n",
    "\"I've never really resented hard work because I've always liked it. Up every morning for roadwork. Going to the gymnasium every day at 12 o'clock. I never change my pattern.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKeHrzNmkopX"
   },
   "source": [
    "## Cycle 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEbWvbYKkopZ"
   },
   "source": [
    "Download the dataset from the link above, then load up the **parkinsons.data** into a variable **X**, being sure to drop the name column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "9G6Oi5d4kopa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <th>...</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>status</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>spread1</th>\n",
       "      <th>spread2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phon_R01_S01_1</td>\n",
       "      <td>119.992</td>\n",
       "      <td>157.302</td>\n",
       "      <td>74.997</td>\n",
       "      <td>0.00784</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.01109</td>\n",
       "      <td>0.04374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06545</td>\n",
       "      <td>0.02211</td>\n",
       "      <td>21.033</td>\n",
       "      <td>1</td>\n",
       "      <td>0.414783</td>\n",
       "      <td>0.815285</td>\n",
       "      <td>-4.813031</td>\n",
       "      <td>0.266482</td>\n",
       "      <td>2.301442</td>\n",
       "      <td>0.284654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phon_R01_S01_2</td>\n",
       "      <td>122.400</td>\n",
       "      <td>148.650</td>\n",
       "      <td>113.819</td>\n",
       "      <td>0.00968</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>0.00696</td>\n",
       "      <td>0.01394</td>\n",
       "      <td>0.06134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09403</td>\n",
       "      <td>0.01929</td>\n",
       "      <td>19.085</td>\n",
       "      <td>1</td>\n",
       "      <td>0.458359</td>\n",
       "      <td>0.819521</td>\n",
       "      <td>-4.075192</td>\n",
       "      <td>0.335590</td>\n",
       "      <td>2.486855</td>\n",
       "      <td>0.368674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phon_R01_S01_3</td>\n",
       "      <td>116.682</td>\n",
       "      <td>131.111</td>\n",
       "      <td>111.555</td>\n",
       "      <td>0.01050</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00544</td>\n",
       "      <td>0.00781</td>\n",
       "      <td>0.01633</td>\n",
       "      <td>0.05233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08270</td>\n",
       "      <td>0.01309</td>\n",
       "      <td>20.651</td>\n",
       "      <td>1</td>\n",
       "      <td>0.429895</td>\n",
       "      <td>0.825288</td>\n",
       "      <td>-4.443179</td>\n",
       "      <td>0.311173</td>\n",
       "      <td>2.342259</td>\n",
       "      <td>0.332634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phon_R01_S01_4</td>\n",
       "      <td>116.676</td>\n",
       "      <td>137.871</td>\n",
       "      <td>111.366</td>\n",
       "      <td>0.00997</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00502</td>\n",
       "      <td>0.00698</td>\n",
       "      <td>0.01505</td>\n",
       "      <td>0.05492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08771</td>\n",
       "      <td>0.01353</td>\n",
       "      <td>20.644</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434969</td>\n",
       "      <td>0.819235</td>\n",
       "      <td>-4.117501</td>\n",
       "      <td>0.334147</td>\n",
       "      <td>2.405554</td>\n",
       "      <td>0.368975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phon_R01_S01_5</td>\n",
       "      <td>116.014</td>\n",
       "      <td>141.781</td>\n",
       "      <td>110.655</td>\n",
       "      <td>0.01284</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.00655</td>\n",
       "      <td>0.00908</td>\n",
       "      <td>0.01966</td>\n",
       "      <td>0.06425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.01767</td>\n",
       "      <td>19.649</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417356</td>\n",
       "      <td>0.823484</td>\n",
       "      <td>-3.747787</td>\n",
       "      <td>0.234513</td>\n",
       "      <td>2.332180</td>\n",
       "      <td>0.410335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
       "0  phon_R01_S01_1      119.992       157.302        74.997         0.00784   \n",
       "1  phon_R01_S01_2      122.400       148.650       113.819         0.00968   \n",
       "2  phon_R01_S01_3      116.682       131.111       111.555         0.01050   \n",
       "3  phon_R01_S01_4      116.676       137.871       111.366         0.00997   \n",
       "4  phon_R01_S01_5      116.014       141.781       110.655         0.01284   \n",
       "\n",
       "   MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  ...  \\\n",
       "0           0.00007   0.00370   0.00554     0.01109       0.04374  ...   \n",
       "1           0.00008   0.00465   0.00696     0.01394       0.06134  ...   \n",
       "2           0.00009   0.00544   0.00781     0.01633       0.05233  ...   \n",
       "3           0.00009   0.00502   0.00698     0.01505       0.05492  ...   \n",
       "4           0.00011   0.00655   0.00908     0.01966       0.06425  ...   \n",
       "\n",
       "   Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
       "0      0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
       "1      0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
       "2      0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
       "3      0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
       "4      0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
       "\n",
       "    spread2        D2       PPE  \n",
       "0  0.266482  2.301442  0.284654  \n",
       "1  0.335590  2.486855  0.368674  \n",
       "2  0.311173  2.342259  0.332634  \n",
       "3  0.334147  2.405554  0.368975  \n",
       "4  0.234513  2.332180  0.410335  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .. your code here ..\n",
    "import pandas as pd\n",
    "df = pd.read_csv('parkinsons.data')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Ixw-1DImf_K"
   },
   "source": [
    "Splice out the status column into a variable **y** and delete it from **X**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "nOWlWytYm0VV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 195 entries, 0 to 194\n",
      "Data columns (total 24 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   name              195 non-null    object \n",
      " 1   MDVP:Fo(Hz)       195 non-null    float64\n",
      " 2   MDVP:Fhi(Hz)      195 non-null    float64\n",
      " 3   MDVP:Flo(Hz)      195 non-null    float64\n",
      " 4   MDVP:Jitter(%)    195 non-null    float64\n",
      " 5   MDVP:Jitter(Abs)  195 non-null    float64\n",
      " 6   MDVP:RAP          195 non-null    float64\n",
      " 7   MDVP:PPQ          195 non-null    float64\n",
      " 8   Jitter:DDP        195 non-null    float64\n",
      " 9   MDVP:Shimmer      195 non-null    float64\n",
      " 10  MDVP:Shimmer(dB)  195 non-null    float64\n",
      " 11  Shimmer:APQ3      195 non-null    float64\n",
      " 12  Shimmer:APQ5      195 non-null    float64\n",
      " 13  MDVP:APQ          195 non-null    float64\n",
      " 14  Shimmer:DDA       195 non-null    float64\n",
      " 15  NHR               195 non-null    float64\n",
      " 16  HNR               195 non-null    float64\n",
      " 17  status            195 non-null    int64  \n",
      " 18  RPDE              195 non-null    float64\n",
      " 19  DFA               195 non-null    float64\n",
      " 20  spread1           195 non-null    float64\n",
      " 21  spread2           195 non-null    float64\n",
      " 22  D2                195 non-null    float64\n",
      " 23  PPE               195 non-null    float64\n",
      "dtypes: float64(22), int64(1), object(1)\n",
      "memory usage: 36.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# .. your code here ..\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['status'].values\n",
    "X = df.drop(columns=['name','status']).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ag3LaZ_fm2bX"
   },
   "source": [
    "Perform a train/test split. **30**% test group size, with a random_state equal to **7**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "HJVbkRsvnD3K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (136, 22) (136,)\n",
      "Test set: (59, 22) (59,)\n"
     ]
    }
   ],
   "source": [
    "# .. your code here ..\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=7)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-gCEYNFnK3Q"
   },
   "source": [
    "Create a SVC classifier. Don't specify any parameters, just leave everything as default. Fit it against your training data and then score your testing data with accuracy and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "GPuI1e4enNjd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg F1-score: 0.7303\n",
      "Jaccard score: 0.7544\n"
     ]
    }
   ],
   "source": [
    "# .. your code here ..\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import jaccard_score\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train) \n",
    "yhat = clf.predict(X_test)\n",
    "print(\"Avg F1-score: %.4f\" % f1_score(y_test, yhat, average='weighted'))\n",
    "print(\"Jaccard score: %.4f\" % jaccard_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2H8GDqSFnPu6"
   },
   "source": [
    "## Cycle 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TrUv89B0nV9U"
   },
   "source": [
    "That accuracy was just too low to be useful. We need to get it up. One way you could go about doing that would be to manually try a bunch of combinations of **C, and gamma values for your rbf kernel**. But that could literally take forever. Also, you might unknowingly skip a pair of values that would have resulted in a very good accuracy.\n",
    "\n",
    "Instead, lets get the computer to do what computers do best. Program a naive, best-parameter search by creating nested for-loops. The outer for-loop should iterate a variable **C from 0.05 to 2, using 0.05 unit increments**. The inner for-loop should increment a variable **gamma from 0.001 to 0.1, using 0.001 unit increments**. As you know, Python ranges won't allow for float intervals, so you'll have to do some research on NumPy ARanges, if you don't already know how to use them.\n",
    "\n",
    "Since the goal is to find the parameters that result in the model having the best accuracy score, you'll need a **best_score = 0 variable that you initialize outside of the for-loops.** Inside the inner for-loop, create an SVC model and pass in the C and gamma parameters its class constructor. Train and score the model appropriately. If the current best_score is less than the model's score, update the best_score being sure to print it out, along with the C and gamma values that resulted in it.\n",
    "\n",
    "After running your lab again, what are the highest accuracy and F1 score you are able to get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "efWGEUPNnO0E"
   },
   "outputs": [],
   "source": [
    "# .. your code here ..\n",
    "c_att = np.linspace(0.05,2,40)\n",
    "g_att = np.linspace(0.001,0.1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 score: 0.9062435235495003 @ C = 1.65 & gamma = 0.005\n",
      "Best Jaccard score: 0.9038461538461539 @ C = 1.65 & gamma = 0.005\n"
     ]
    }
   ],
   "source": [
    "best_f1_score = 0\n",
    "best_jaccard_score = 0\n",
    "C,G = 0,0\n",
    "for c in c_att:\n",
    "    for g in g_att:\n",
    "        clf = svm.SVC(C = c, gamma = g)\n",
    "        clf.fit(X_train, y_train) \n",
    "        yhat = clf.predict(X_test)\n",
    "        if (f1_score(y_test, yhat, average='weighted') > best_f1_score):\n",
    "            best_f1_score = f1_score(y_test, yhat, average='weighted')\n",
    "            best_jaccard_score = jaccard_score(y_test,yhat)\n",
    "            C = c\n",
    "            G = g\n",
    "print('Best F1 score:',best_f1_score,'@ C =',C,'& gamma =',G)\n",
    "print('Best Jaccard score:',best_jaccard_score,'@ C =',C,'& gamma =',G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZev_qCYnylw"
   },
   "source": [
    "## Cycle 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqM4tWC4n_Gk"
   },
   "source": [
    "Wait a second. Pull open the dataset's label file from: https://archive.ics.uci.edu/ml/datasets/Parkinsons\n",
    "\n",
    "Look at the units on those columns: **Hz, %, Abs, dB, etc.** What happened to transforming your data? With all of those units interacting with one another, some pre-processing is surely in order.\n",
    "Right after you preform the train/test split but before you train your model, inject SciKit-Learn's pre-processing code. Unless you have a good idea which one is going to work best, you're going to have to try the various pre-processors one at a time, checking to see if they improve your predictive accuracy.\n",
    "\n",
    "Experiment with ***Normalizer(), MaxAbsScaler(), MinMaxScaler(), KernelCenterer(), and StandardScaler().***\n",
    "\n",
    "After trying all of these scalers, what are the new highest accuracy and F1 score you're able to achieve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "i828Tr31n-Nu"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 score: 0.7064278861528621 @ C = 0.05 & gamma = 0.001\n",
      "Best Jaccard score: 0.7966101694915254 @ C = 0.05 & gamma = 0.001\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=7)\n",
    "normalizer = preprocessing.Normalizer()\n",
    "X_train = normalizer.fit_transform(X_train)\n",
    "X_test = normalizer.fit_transform(X_test)\n",
    "\n",
    "best_f1_score = 0\n",
    "best_jaccard_score = 0\n",
    "C,G = 0,0\n",
    "for c in c_att:\n",
    "    for g in g_att:\n",
    "        clf = svm.SVC(C = c, gamma = g)\n",
    "        clf.fit(X_train, y_train) \n",
    "        yhat = clf.predict(X_test)\n",
    "        if (f1_score(y_test, yhat, average='weighted') > best_f1_score):\n",
    "            best_f1_score = f1_score(y_test, yhat, average='weighted')\n",
    "            best_jaccard_score = jaccard_score(y_test,yhat)\n",
    "            C = c\n",
    "            G = g\n",
    "print('Best F1 score:',best_f1_score,'@ C =',C,'& gamma =',G)\n",
    "print('Best Jaccard score:',best_jaccard_score,'@ C =',C,'& gamma =',G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 score: 0.861040640454873 @ C = 1.2 & gamma = 0.1\n",
      "Best Jaccard score: 0.8703703703703703 @ C = 1.2 & gamma = 0.1\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=7)\n",
    "maxabsscaler = preprocessing.MaxAbsScaler()\n",
    "X_train = maxabsscaler.fit_transform(X_train)\n",
    "X_test = maxabsscaler.fit_transform(X_test)\n",
    "\n",
    "best_f1_score = 0\n",
    "best_jaccard_score = 0\n",
    "C,G = 0,0\n",
    "for c in c_att:\n",
    "    for g in g_att:\n",
    "        clf = svm.SVC(C = c, gamma = g)\n",
    "        clf.fit(X_train, y_train) \n",
    "        yhat = clf.predict(X_test)\n",
    "        if (f1_score(y_test, yhat, average='weighted') > best_f1_score):\n",
    "            best_f1_score = f1_score(y_test, yhat, average='weighted')\n",
    "            best_jaccard_score = jaccard_score(y_test,yhat)\n",
    "            C = c\n",
    "            G = g\n",
    "print('Best F1 score:',best_f1_score,'@ C =',C,'& gamma =',G)\n",
    "print('Best Jaccard score:',best_jaccard_score,'@ C =',C,'& gamma =',G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 score: 0.861040640454873 @ C = 0.75 & gamma = 0.094\n",
      "Best Jaccard score: 0.8703703703703703 @ C = 0.75 & gamma = 0.094\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=7)\n",
    "minmaxscaler = preprocessing.MinMaxScaler()\n",
    "X_train = minmaxscaler.fit_transform(X_train)\n",
    "X_test = minmaxscaler.fit_transform(X_test)\n",
    "best_f1_score = 0\n",
    "best_jaccard_score = 0\n",
    "C,G = 0,0\n",
    "for c in c_att:\n",
    "    for g in g_att:\n",
    "        clf = svm.SVC(C = c, gamma = g)\n",
    "        clf.fit(X_train, y_train) \n",
    "        yhat = clf.predict(X_test)\n",
    "        if (f1_score(y_test, yhat, average='weighted') > best_f1_score):\n",
    "            best_f1_score = f1_score(y_test, yhat, average='weighted')\n",
    "            best_jaccard_score = jaccard_score(y_test,yhat)\n",
    "            C = c\n",
    "            G = g\n",
    "print('Best F1 score:',best_f1_score,'@ C =',C,'& gamma =',G)\n",
    "print('Best Jaccard score:',best_jaccard_score,'@ C =',C,'& gamma =',G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Kernel matrix must be a square matrix. Input is a 136x22 matrix.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-a0aaeea58f7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mkernelcenterer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKernelCenterer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkernelcenterer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkernelcenterer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data_analytic\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    697\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data_analytic\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, K, y)\u001b[0m\n\u001b[0;32m   2276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2277\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2278\u001b[1;33m             raise ValueError(\"Kernel matrix must be a square matrix.\"\n\u001b[0m\u001b[0;32m   2279\u001b[0m                              \u001b[1;34m\" Input is a {}x{} matrix.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2280\u001b[0m                              .format(K.shape[0], K.shape[1]))\n",
      "\u001b[1;31mValueError\u001b[0m: Kernel matrix must be a square matrix. Input is a 136x22 matrix."
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=7)\n",
    "kernelcenterer = preprocessing.KernelCenterer()\n",
    "X_train = kernelcenterer.fit_transform(X_train)\n",
    "X_test = kernelcenterer.fit_transform(X_test)\n",
    "\n",
    "best_f1_score = 0\n",
    "best_jaccard_score = 0\n",
    "C,G = 0,0\n",
    "for c in c_att:\n",
    "    for g in g_att:\n",
    "        clf = svm.SVC(C = c, gamma = g)\n",
    "        clf.fit(X_train, y_train) \n",
    "        yhat = clf.predict(X_test)\n",
    "        if (f1_score(y_test, yhat, average='weighted') > best_f1_score):\n",
    "            best_f1_score = f1_score(y_test, yhat, average='weighted')\n",
    "            best_jaccard_score = jaccard_score(y_test,yhat)\n",
    "            C = c\n",
    "            G = g\n",
    "print('Best F1 score:',best_f1_score,'@ C =',C,'& gamma =',G)\n",
    "print('Best Jaccard score:',best_jaccard_score,'@ C =',C,'& gamma =',G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 score: 0.9649139702105802 @ C = 1.9 & gamma = 0.1\n",
      "Best Jaccard score: 0.9591836734693877 @ C = 1.9 & gamma = 0.1\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=7)\n",
    "standardscaler = preprocessing.StandardScaler()\n",
    "X_train = standardscaler.fit_transform(X_train)\n",
    "X_test = standardscaler.fit_transform(X_test)\n",
    "\n",
    "best_f1_score = 0\n",
    "best_jaccard_score = 0\n",
    "C,G = 0,0\n",
    "for c in c_att:\n",
    "    for g in g_att:\n",
    "        clf = svm.SVC(C = c, gamma = g)\n",
    "        clf.fit(X_train, y_train) \n",
    "        yhat = clf.predict(X_test)\n",
    "        if (f1_score(y_test, yhat, average='weighted') > best_f1_score):\n",
    "            best_f1_score = f1_score(y_test, yhat, average='weighted')\n",
    "            best_jaccard_score = jaccard_score(y_test,yhat)\n",
    "            C = c\n",
    "            G = g\n",
    "print('Best F1 score:',best_f1_score,'@ C =',C,'& gamma =',G)\n",
    "print('Best Jaccard score:',best_jaccard_score,'@ C =',C,'& gamma =',G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [
    "JKeHrzNmkopX",
    "2H8GDqSFnPu6",
    "RZev_qCYnylw"
   ],
   "name": "Lab 6.2-Muhammad Ali.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "58px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
