{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "toc": {
      "colors": {
        "hover_highlight": "#DAA520",
        "running_highlight": "#FF0000",
        "selected_highlight": "#FFD700"
      },
      "moveMenuLeft": true,
      "nav_menu": {
        "height": "58px",
        "width": "252px"
      },
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 4,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false,
      "widenNotebook": false
    },
    "colab": {
      "name": "Lab 3.2-diagnosis of breast cancer.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qsQxbvputRtY",
        "FPKg-N2jvUry",
        "MxOOC1ksvZXc"
      ],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsQxbvputRtY"
      },
      "source": [
        "## Lab Introduction\n",
        "Breast cancer usually starts from an uncontrolled growth of the cells that make up the milk-producing ducts. While fairly uncommon with men (less than 0.1% experience it), according to BreastCancer.org, one in eight women (12%) end up developing a malignant form of breast cancer over the course of their lifetime. These invasive cells form tumors that destroy nearby tissue, can spread to other parts of the body, and if not duly addressed, may result in death. To put things into perspective, in the U.S., roughly 600 women die per year due to pregnancy related complications... yet over 40,000 die per year due to breast cancer.\n",
        "\n",
        "Breast cancer doesn't develop over night and, like any other cancer, can be treated extremely effectively if detected in its earlier stages. Part of the understanding cancer is knowing that not all irregular cell growths are malignant; some are benign, or non-dangerous, non-cancerous growths. A benign tumor does not mean the mass doesn't increase in size, but only means it does not pose a threat to nearby tissue, nor is it likely to spread to other parts of the body. The mass simply stays wherever it's growing. Benign tumors are actually pretty popular, such as moles and some warts. Being able to properly assess if a tumor is actually benign and ignorable, or malignant and alarming is therefore of importance, and also is a problem that might be solvable through data and machine learning.\n",
        "\n",
        "In this lab, you'll be using the **[Breast Cancer Wisconsin Original](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Original))**  data set, provided courtesy of UCI's Machine Learning Repository. Here are the column names, which you can read more details about on the dataset's information page:\n",
        "\n",
        "**['sample', 'thickness', 'size', 'shape', 'adhesion', 'epithelial', 'nuclei', 'chromatin', 'nucleoli', 'mitoses', 'status']**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybrJc_3xtRtd"
      },
      "source": [
        "import random, math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "matplotlib.style.use('ggplot') # Look Pretty\n",
        "\n",
        "\n",
        "# Leave this alone until indicated:\n",
        "Test_PCA = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qD4KY8ztRtm"
      },
      "source": [
        "### A Convenience Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsStrakJtRto"
      },
      "source": [
        "This method is for your visualization convenience only. You aren't expected to know how to put this together yourself, although you should be able to follow the code by now:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcJlMLSRtRtq"
      },
      "source": [
        "def plotDecisionBoundary(model, X, y):\n",
        "    print(\"Plotting...\")\n",
        "\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "\n",
        "    padding = 0.1\n",
        "    resolution = 0.1\n",
        "\n",
        "    #(2 for benign, 4 for malignant)\n",
        "    colors = {2:'royalblue', 4:'lightsalmon'} \n",
        "\n",
        "\n",
        "    # Calculate the boundaris\n",
        "    x_min, x_max = X[:, 0].min(), X[:, 0].max()\n",
        "    y_min, y_max = X[:, 1].min(), X[:, 1].max()\n",
        "    x_range = x_max - x_min\n",
        "    y_range = y_max - y_min\n",
        "    x_min -= x_range * padding\n",
        "    y_min -= y_range * padding\n",
        "    x_max += x_range * padding\n",
        "    y_max += y_range * padding\n",
        "\n",
        "    # Create a 2D Grid Matrix. The values stored in the matrix\n",
        "    # are the predictions of the class at at said location\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, resolution),\n",
        "                         np.arange(y_min, y_max, resolution))\n",
        "\n",
        "    # What class does the classifier say?\n",
        "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    # Plot the contour map\n",
        "    plt.contourf(xx, yy, Z, cmap=plt.cm.seismic)\n",
        "    plt.axis('tight')\n",
        "\n",
        "    # Plot your testing points as well...\n",
        "    for label in np.unique(y):\n",
        "        indices = np.where(y == label)\n",
        "        plt.scatter(X[indices, 0], X[indices, 1], c=colors[label], alpha=0.8)\n",
        "\n",
        "    p = model.get_params()\n",
        "    plt.title('K = ' + str(p['n_neighbors']))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "U7_wk7wftRtx"
      },
      "source": [
        "## 1. Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "UvBzWvYvtRty"
      },
      "source": [
        "Firstly, download the the [dataset](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Original)). Then, load in the dataset (**breast-cancer-wisconsin.data**), identify nans, and set proper headers. Be sure to verify the rows line up by looking at the file in a text editor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-_pz4s8tRt0"
      },
      "source": [
        "# .. your code here .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSmvSbGjtRt7"
      },
      "source": [
        "Copy out the status column into a slice, then drop it from the main dataframe. Always verify you properly executed the drop by double checking (printing out the resulting operating)! Many people forget to set the right axis here.\n",
        "\n",
        "If you goofed up on loading the dataset and notice you have a `sample` column, this would be a good place to drop that too if you haven't already."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pc8PoOVttRt9"
      },
      "source": [
        "# .. your code here .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "C-3Lo9TKtRuG"
      },
      "source": [
        "With the labels safely extracted from the dataset, replace any nan values with the mean feature / column value:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjiufhQqtRuH"
      },
      "source": [
        "# .. your code here .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elH_BYtEtRuO"
      },
      "source": [
        "Do train_test_split. Use the same variable names as on the EdX platform in the reading material, but set the random_state=7 for reproducibility, and keep the test_size at 0.5 (50%)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6l5zha1tRuP"
      },
      "source": [
        "# .. your code here .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daokpc-8tRuV"
      },
      "source": [
        "Experiment with the basic SKLearn preprocessing scalers. We know that the features consist of different units mixed in together, so it might be reasonable to assume feature scaling is necessary. Print out a description of the dataset, post transformation. Recall: when you do pre-processing, which portion of the dataset is your model trained upon? Also which portion(s) of your dataset actually get transformed?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmOgVKtGtRuW"
      },
      "source": [
        "# .. your code here .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yq7ZY--PtRud"
      },
      "source": [
        "### Dimensionality Reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPONsL9-tRue"
      },
      "source": [
        "[PCA](https://blog.paperspace.com/dimension-reduction-with-principal-component-analysis/) and [Isomap](https://https://blog.paperspace.com/dimension-reduction-with-isomap/) are your new best friends"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDt5EqiAtRuf"
      },
      "source": [
        "model = None\n",
        "if Test_PCA:\n",
        "    print(\"Computing 2D Principle Components\")\n",
        "    model = PCA(n_components=2)\n",
        "else:\n",
        "    print(\"Computing 2D Isomap Manifold\")\n",
        "model = Isomap(n_neighbors=5, n_components=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPKg-N2jvUry"
      },
      "source": [
        "## 2. Training the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQJILS-StRum"
      },
      "source": [
        "Train your model against data_train, then transform both `data_train` and `data_test` using your model. You can save the results right back into the variables themselves."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiaqyS7qtRun"
      },
      "source": [
        "# .. your code here .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJ2MFLPUtRuv"
      },
      "source": [
        "Implement and train `KNeighborsClassifier` on your projected 2D training data here. You can name your variable `knmodel`. You can use any `K` value from 1 - 15, so play around with it and see what results you can come up. Your goal is to find a good balance where you aren't too specific (low-K), nor are you too general (high-K). You should also experiment with how changing the weights parameter affects the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aPRKB-vtRuw"
      },
      "source": [
        "# .. your code here .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "8_fUw8XTtRu2"
      },
      "source": [
        "Be sure to always keep the domain of the problem in mind! It's WAY more important to errantly classify a benign tumor as malignant, and have it removed, than to incorrectly leave a malignant tumor, believing it to be benign, and then having the patient progress in cancer. Since the UDF weights don't give you any class information, the only way to introduce this data into SKLearn's KNN Classifier is by \"baking\" it into your data. For example, randomly reducing the ratio of benign samples compared to malignant samples from the training set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxOOC1ksvZXc"
      },
      "source": [
        "## 3. Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "K3Jio_zStRu3"
      },
      "source": [
        "Calculate and display the accuracy and F1 score of the testing set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrCku8-MtRu4"
      },
      "source": [
        "# .. your code changes above .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OxSR4GHtRu9"
      },
      "source": [
        "plotDecisionBoundary(knmodel, X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}